{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BayesianSearchCV\n",
        "\n",
        "1. Apa itu hyperparameter tuning?\n",
        "\n",
        "    Hyperparameter tuning (penyetelan hyperparameter) adalah proses mencari nilai optimal untuk hyperparameter suatu model machine learning atau deep learning untuk mencapai kinerja model terbaik pada tugas yang dimaksud.\n",
        "\n",
        "\n",
        "2. Jelaskan metode BayesSearchCV!\n",
        "\n",
        "    BayesSearchCV adalah metode hyperparameter tuning yang menggunakan Optimasi Bayesian untuk mencari kombinasi hyperparameter optimal secara lebih efisien dibandingkan dengan metode tradisional seperti Grid Search atau Random Search.\n",
        "3. Bagaimana cara kerja BayesSearchCV?\n",
        "\n",
        "    BayesSearchCV bekerja berdasarkan prinsip Optimasi Bayesian, yang menggunakan model probabilitas untuk secara cerdas memilih kombinasi hyperparameter berikutnya yang akan diuji. Tujuannya adalah menemukan nilai optimal dengan evaluasi model yang jauh lebih sedikit dibandingkan Grid Search atau Random Search.\n",
        "\n",
        "4. Apa kelebihan BayesSearchCV dibandingkan metode hyperparameter tuning lainnya?\n",
        "\n",
        "    Hyperparameter Tuning adalah proses penting dalam machine learning untuk mencari nilai optimal dari hyperparameter sebuah model yang harus diatur sebelum pelatihan dimulai. Tujuannya adalah memastikan model mencapai kinerja terbaik, yaitu berakurat tinggi tanpa mengalami overfitting atau underfittingâ€”pada data yang belum pernah dilihat. Proses ini pada dasarnya adalah eksperimen berulang, di mana berbagai kombinasi hyperparameter diuji dan dibandingkan menggunakan metrik kinerja, sehingga model yang dihasilkan benar-benar efektif dan efisien.\n"
      ],
      "metadata": {
        "id": "pjbXCL2nNB9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2o0dt8txGE1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a355cce4-d44d-4223-8e88-2d3c76a36f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-optimize # install jika belum pernah install\n",
        "!pip install scikit-optimize\n",
        "\n",
        "# import library\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "X, y = loaX, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n"
      ],
      "metadata": {
        "id": "v7ENirBIHIYz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan Model dan parameter yang akan dioptimasi (Ruang Hyperparameter)\n",
        "model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': Integer(50, 300),\n",
        "    'max_depth': Integer(2, 20),\n",
        "    'min_samples_split': Integer(2, 20),\n",
        "    'min_samples_leaf': Integer(1, 20),\n",
        "    'max_features': Categorical(['sqrt', 'log2', None])\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "vmyqOLU1IO3T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fungsi Optimisasi Menggunakan BayesianSearchCV"
      ],
      "metadata": {
        "id": "Ip5U8cL4OLUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi BayesSearchCV\n",
        "opt = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=32,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    random_state=0\n",
        ")"
      ],
      "metadata": {
        "id": "BC0k0vXKOBJk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan optimisasi\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Score:\", opt.best_score_)\n",
        "print(\"Best Parameters:\", opt.best_params_)"
      ],
      "metadata": {
        "id": "EYoUwsYCOB5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7695bb-a49a-4a69-9d09-4eb2b2fd6662"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.9731225296442687\n",
            "Best Parameters: OrderedDict({'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 11, 'min_samples_split': 9, 'n_estimators': 50})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi Model\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sox5OZx6OD0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0647d6-0703-4b8b-ce7d-7c0e310ba3c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9736842105263158\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      0.94      0.97        16\n",
            "           2       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        38\n",
            "   macro avg       0.97      0.98      0.97        38\n",
            "weighted avg       0.98      0.97      0.97        38\n",
            "\n"
          ]
        }
      ]
    }
  ]
}